{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import norm\n",
    "from numpy import repeat, dot\n",
    "from numpy.linalg import inv\n",
    "from numpy import ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X+np.random.normal(0,0.001, (X.shape))\n",
    "        self.y = y\n",
    "        self.obs, self.n = X.shape\n",
    "        assert(self.obs==y.shape[0])\n",
    "        self.classes = np.unique(y)\n",
    "        self.nclass = len(self.classes)\n",
    "        \n",
    "    def _train(self):\n",
    "        self.prior = [np.sum(self.y == c) / self.y.size for c in self.classes]\n",
    "        self.aprior = [np.sum(self.y == c) for c in self.classes]\n",
    "        self._compute_mean_and_sigma()\n",
    "    \n",
    "    def _predict_score(self, Xt):\n",
    "        rows,n_t = Xt.shape\n",
    "        posterior = np.zeros((rows, self.nclass))\n",
    "        logprior = [np.log(p) for p in self.prior]\n",
    "        \n",
    "        assert(self.n==n_t)\n",
    "        \n",
    "        for j in range(rows):\n",
    "            for i in range(self.nclass):\n",
    "                c=self.classes[i]\n",
    "                lpck=logprior[i]\n",
    "                sdp=1\n",
    "                standardDeviationOfThisClass=self.std[c]\n",
    "                for e in range(self.n):\n",
    "                    sdp *= standardDeviationOfThisClass[e]\n",
    "                firstTerm = np.log(1/sdp)\n",
    "                \n",
    "                meanOfThisClass=self.mu[c]\n",
    "                anotherTerm=0\n",
    "                for e in range(self.n):\n",
    "                    anotherTerm += (Xt[j,e] - meanOfThisClass[e])**2/ 2*(standardDeviationOfThisClass[e]**2)\n",
    "                posterior[j,i]=firstTerm-anotherTerm+lpck\n",
    "        return posterior\n",
    "        \n",
    "    def _predict_class(self, score):\n",
    "        pred = np.argmax(score, axis=1)\n",
    "        return np.array([self.classes[i] for i in pred])\n",
    "        \n",
    "    def predict(self, Xt):\n",
    "        #print(\"Score to be calculated\")\n",
    "        score = self._predict_score(Xt)\n",
    "        #print(\"Score calculated\")\n",
    "        return self._predict_class(score)\n",
    "    \n",
    "    def validate(self, Xt, yt):\n",
    "        Xt += np.random.normal(0,0.001, (Xt.shape))\n",
    "        mypredictions=self.predict(Xt)\n",
    "        return self.calc_error(mypredictions, yt)\n",
    "        \n",
    "    def calc_error(self, ynew, target):\n",
    "        correctness = np.array([yn == y for (yn,y) in zip(ynew, target)])\n",
    "        return 1 - (np.sum(correctness) / target.size)\n",
    "    \n",
    "    def build(self):\n",
    "        self.Xeach=self._split_by_class(self.X, self.y)\n",
    "        self._train()\n",
    "        return self\n",
    "    \n",
    "    def _split_by_class(self, X, y):\n",
    "        return {c:X[np.where(y==c)[0],:] for c in self.classes}\n",
    "    \n",
    "    def _compute_mean_and_sigma(self):\n",
    "        self.mu={c:np.mean(self.Xeach[c], axis=0).reshape(self.n,-1) for c in self.classes}\n",
    "        self.sigma={c:np.var(self.Xeach[c], axis=0).reshape(self.n,-1) for c in self.classes}\n",
    "        self.std={c:np.std(self.Xeach[c], axis=0, ddof=1).reshape(self.n,-1) for c in self.classes}\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#select % of random sub-indices out of the given dataset\n",
    "def rsubindices(dSet, percent):\n",
    "    r,_ = dSet.shape\n",
    "    if not r:\n",
    "        return np.ndarray(shape=(0,))  \n",
    "    indices=np.arange(r)\n",
    "    return np.random.choice(indices, math.ceil(percent/100*len(indices)), replace=False)\n",
    "\n",
    "def naiveBayesGaussian(filename, num_splits, train_percent=[10,25,50,75,100]):\n",
    "    # from sklearn.datasets import load_boston\n",
    "    # boston = load_boston()\n",
    "    assert os.path.isfile(filename) and os.access(filename, os.R_OK)\n",
    "    df=pd.read_csv(filename, sep=',', header = None)\n",
    "    #print(df.shape)\n",
    "    #df.head()\n",
    "    \n",
    "    data = df.as_matrix()\n",
    "    X=data[:, :-1]\n",
    "    y=data[:, -1]\n",
    "    #assert(all(y==boston.target))\n",
    "    del df, data\n",
    "    \n",
    "    X=X+np.random.normal(0, 0.001, X.shape) #to prevent numerical problem\n",
    "    \n",
    "    if len(np.unique(y))>15:\n",
    "        # if the target values are more than some reasonable no (15), we take that as binary classifier\n",
    "        b = np.percentile(y, 50)\n",
    "        f=np.vectorize(lambda x: 0 if x<b else 1)\n",
    "        y=f(y)\n",
    "        assert(X.shape[0]==y.shape[0])\n",
    "        y=np.reshape(y, [X.shape[0], 1])\n",
    "\n",
    "    errormatrix = np.zeros( (num_splits, len(train_percent)) )\n",
    "    # perform for num-splits iterations\n",
    "    for i in range(num_splits):\n",
    "        print(\"------------------------------------------------------------\")\n",
    "        print(\" splitting the input data-frame into 80-20 train-test data..\")\n",
    "        print(\"------------------------------------------------------------\")\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.2)\n",
    "        Y_train = np.reshape(Y_train, [X_train.shape[0], 1])\n",
    "        Y_test = np.reshape(Y_test, [X_test.shape[0], 1])\n",
    "        \n",
    "        # percentage of data to be used for the model\n",
    "        for j,p in enumerate(train_percent):\n",
    "            selection = rsubindices(Y_train, p)\n",
    "            train = X_train[selection, :]\n",
    "            labels= Y_train[selection]\n",
    "            model = NaiveBayes(train,labels).build()\n",
    "            e = model.validate(X_test, Y_test)\n",
    "            print(\"Error-rate with train-percent %s :\" % p, e)\n",
    "            errormatrix[i, j] = e\n",
    "        print()\n",
    "\n",
    "    errmu = np.mean(errormatrix, axis=0)\n",
    "    errsigma = np.std(errormatrix, axis=0, ddof=1)\n",
    "    \n",
    "    print(\"Mean test-error\"+str(errmu))\n",
    "    print(\"Std test-error\"+str(errsigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      " splitting the input data-frame into 80-20 train-test data..\n",
      "------------------------------------------------------------\n",
      "Error-rate with train-percent 10 : 0.421568627451\n",
      "Error-rate with train-percent 25 : 0.294117647059\n",
      "Error-rate with train-percent 50 : 0.343137254902\n",
      "Error-rate with train-percent 75 : 0.303921568627\n",
      "Error-rate with train-percent 100 : 0.303921568627\n",
      "\n",
      "------------------------------------------------------------\n",
      " splitting the input data-frame into 80-20 train-test data..\n",
      "------------------------------------------------------------\n",
      "Error-rate with train-percent 10 : 0.43137254902\n",
      "Error-rate with train-percent 25 : 0.441176470588\n",
      "Error-rate with train-percent 50 : 0.470588235294\n",
      "Error-rate with train-percent 75 : 0.460784313725\n",
      "Error-rate with train-percent 100 : 0.450980392157\n",
      "\n",
      "------------------------------------------------------------\n",
      " splitting the input data-frame into 80-20 train-test data..\n",
      "------------------------------------------------------------\n",
      "Error-rate with train-percent 10 : 0.352941176471\n",
      "Error-rate with train-percent 25 : 0.352941176471\n",
      "Error-rate with train-percent 50 : 0.392156862745\n",
      "Error-rate with train-percent 75 : 0.392156862745\n",
      "Error-rate with train-percent 100 : 0.362745098039\n",
      "\n",
      "------------------------------------------------------------\n",
      " splitting the input data-frame into 80-20 train-test data..\n",
      "------------------------------------------------------------\n",
      "Error-rate with train-percent 10 : 0.333333333333\n",
      "Error-rate with train-percent 25 : 0.333333333333\n",
      "Error-rate with train-percent 50 : 0.343137254902\n",
      "Error-rate with train-percent 75 : 0.343137254902\n",
      "Error-rate with train-percent 100 : 0.333333333333\n",
      "\n",
      "------------------------------------------------------------\n",
      " splitting the input data-frame into 80-20 train-test data..\n",
      "------------------------------------------------------------\n",
      "Error-rate with train-percent 10 : 0.303921568627\n",
      "Error-rate with train-percent 25 : 0.294117647059\n",
      "Error-rate with train-percent 50 : 0.28431372549\n",
      "Error-rate with train-percent 75 : 0.313725490196\n",
      "Error-rate with train-percent 100 : 0.303921568627\n",
      "\n",
      "------------------------------------------------------------\n",
      " splitting the input data-frame into 80-20 train-test data..\n",
      "------------------------------------------------------------\n",
      "Error-rate with train-percent 10 : 0.392156862745\n",
      "Error-rate with train-percent 25 : 0.401960784314\n",
      "Error-rate with train-percent 50 : 0.372549019608\n",
      "Error-rate with train-percent 75 : 0.372549019608\n",
      "Error-rate with train-percent 100 : 0.372549019608\n",
      "\n",
      "------------------------------------------------------------\n",
      " splitting the input data-frame into 80-20 train-test data..\n",
      "------------------------------------------------------------\n",
      "Error-rate with train-percent 10 : 0.333333333333\n",
      "Error-rate with train-percent 25 : 0.392156862745\n",
      "Error-rate with train-percent 50 : 0.235294117647\n",
      "Error-rate with train-percent 75 : 0.254901960784\n",
      "Error-rate with train-percent 100 : 0.254901960784\n",
      "\n",
      "------------------------------------------------------------\n",
      " splitting the input data-frame into 80-20 train-test data..\n",
      "------------------------------------------------------------\n",
      "Error-rate with train-percent 10 : 0.323529411765\n",
      "Error-rate with train-percent 25 : 0.392156862745\n",
      "Error-rate with train-percent 50 : 0.411764705882\n",
      "Error-rate with train-percent 75 : 0.362745098039\n",
      "Error-rate with train-percent 100 : 0.382352941176\n",
      "\n",
      "------------------------------------------------------------\n",
      " splitting the input data-frame into 80-20 train-test data..\n",
      "------------------------------------------------------------\n",
      "Error-rate with train-percent 10 : 0.274509803922\n",
      "Error-rate with train-percent 25 : 0.313725490196\n",
      "Error-rate with train-percent 50 : 0.333333333333\n",
      "Error-rate with train-percent 75 : 0.343137254902\n",
      "Error-rate with train-percent 100 : 0.333333333333\n",
      "\n",
      "------------------------------------------------------------\n",
      " splitting the input data-frame into 80-20 train-test data..\n",
      "------------------------------------------------------------\n",
      "Error-rate with train-percent 10 : 0.333333333333\n",
      "Error-rate with train-percent 25 : 0.313725490196\n",
      "Error-rate with train-percent 50 : 0.343137254902\n",
      "Error-rate with train-percent 75 : 0.313725490196\n",
      "Error-rate with train-percent 100 : 0.303921568627\n",
      "\n",
      "Mean test-error[ 0.35        0.35294118  0.35294118  0.34607843  0.34019608]\n",
      "Std test-error[ 0.05042644  0.05125617  0.06535948  0.05623384  0.05469343]\n"
     ]
    }
   ],
   "source": [
    "naiveBayesGaussian('boston.csv', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      " splitting the input data-frame into 80-20 train-test data..\n",
      "------------------------------------------------------------\n",
      "Error-rate with train-percent 10 : 0.388888888889\n",
      "Error-rate with train-percent 25 : 0.405555555556\n",
      "Error-rate with train-percent 50 : 0.391666666667\n",
      "Error-rate with train-percent 75 : 0.361111111111\n",
      "Error-rate with train-percent 100 : 0.366666666667\n",
      "\n",
      "------------------------------------------------------------\n",
      " splitting the input data-frame into 80-20 train-test data..\n",
      "------------------------------------------------------------\n",
      "Error-rate with train-percent 10 : 0.6\n",
      "Error-rate with train-percent 25 : 0.452777777778\n",
      "Error-rate with train-percent 50 : 0.341666666667\n",
      "Error-rate with train-percent 75 : 0.386111111111\n",
      "Error-rate with train-percent 100 : 0.391666666667\n",
      "\n",
      "------------------------------------------------------------\n",
      " splitting the input data-frame into 80-20 train-test data..\n",
      "------------------------------------------------------------\n",
      "Error-rate with train-percent 10 : 0.469444444444\n",
      "Error-rate with train-percent 25 : 0.394444444444\n",
      "Error-rate with train-percent 50 : 0.438888888889\n",
      "Error-rate with train-percent 75 : 0.413888888889\n",
      "Error-rate with train-percent 100 : 0.430555555556\n",
      "\n",
      "------------------------------------------------------------\n",
      " splitting the input data-frame into 80-20 train-test data..\n",
      "------------------------------------------------------------\n",
      "Error-rate with train-percent 10 : 0.436111111111\n",
      "Error-rate with train-percent 25 : 0.358333333333\n",
      "Error-rate with train-percent 50 : 0.402777777778\n",
      "Error-rate with train-percent 75 : 0.333333333333\n",
      "Error-rate with train-percent 100 : 0.355555555556\n",
      "\n",
      "------------------------------------------------------------\n",
      " splitting the input data-frame into 80-20 train-test data..\n",
      "------------------------------------------------------------\n",
      "Error-rate with train-percent 10 : 0.377777777778\n",
      "Error-rate with train-percent 25 : 0.430555555556\n",
      "Error-rate with train-percent 50 : 0.369444444444\n",
      "Error-rate with train-percent 75 : 0.394444444444\n",
      "Error-rate with train-percent 100 : 0.394444444444\n",
      "\n",
      "------------------------------------------------------------\n",
      " splitting the input data-frame into 80-20 train-test data..\n",
      "------------------------------------------------------------\n",
      "Error-rate with train-percent 10 : 0.397222222222\n",
      "Error-rate with train-percent 25 : 0.441666666667\n",
      "Error-rate with train-percent 50 : 0.363888888889\n",
      "Error-rate with train-percent 75 : 0.366666666667\n",
      "Error-rate with train-percent 100 : 0.369444444444\n",
      "\n",
      "------------------------------------------------------------\n",
      " splitting the input data-frame into 80-20 train-test data..\n",
      "------------------------------------------------------------\n",
      "Error-rate with train-percent 10 : 0.580555555556\n",
      "Error-rate with train-percent 25 : 0.461111111111\n",
      "Error-rate with train-percent 50 : 0.422222222222\n",
      "Error-rate with train-percent 75 : 0.394444444444\n",
      "Error-rate with train-percent 100 : 0.366666666667\n",
      "\n",
      "------------------------------------------------------------\n",
      " splitting the input data-frame into 80-20 train-test data..\n",
      "------------------------------------------------------------\n",
      "Error-rate with train-percent 10 : 0.508333333333\n",
      "Error-rate with train-percent 25 : 0.569444444444\n",
      "Error-rate with train-percent 50 : 0.433333333333\n",
      "Error-rate with train-percent 75 : 0.436111111111\n",
      "Error-rate with train-percent 100 : 0.375\n",
      "\n",
      "------------------------------------------------------------\n",
      " splitting the input data-frame into 80-20 train-test data..\n",
      "------------------------------------------------------------\n",
      "Error-rate with train-percent 10 : 0.513888888889\n",
      "Error-rate with train-percent 25 : 0.383333333333\n",
      "Error-rate with train-percent 50 : 0.330555555556\n",
      "Error-rate with train-percent 75 : 0.377777777778\n",
      "Error-rate with train-percent 100 : 0.355555555556\n",
      "\n",
      "------------------------------------------------------------\n",
      " splitting the input data-frame into 80-20 train-test data..\n",
      "------------------------------------------------------------\n",
      "Error-rate with train-percent 10 : 0.458333333333\n",
      "Error-rate with train-percent 25 : 0.461111111111\n",
      "Error-rate with train-percent 50 : 0.394444444444\n",
      "Error-rate with train-percent 75 : 0.391666666667\n",
      "Error-rate with train-percent 100 : 0.394444444444\n",
      "\n",
      "Mean test-error[ 0.47305556  0.43583333  0.38888889  0.38555556  0.38      ]\n",
      "Std test-error[ 0.07752439  0.05856729  0.03719872  0.02847279  0.0230851 ]\n"
     ]
    }
   ],
   "source": [
    "naiveBayesGaussian('digits.csv', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
